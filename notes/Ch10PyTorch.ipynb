{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325d6aa2",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "This chapter:  train/eval/finetine/optimize w/ pytorch. Then, optuna library for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eebf98",
   "metadata": {},
   "source": [
    "## Fundamentals\n",
    "\n",
    "Data type is a tensor. Its a multi-dim array w/shape and datatype. Can live on GPU, and does auto-differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fe3840",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b58dd111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 7.],\n",
       "        [2., 3., 6.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.tensor([[1.0, 4.0, 7.0], [2.0, 3.0, 6.0]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "32245ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors only take one data type. If you give it more than one, the most general type will be selected (complex > float > int > bool)\n",
    "display(X.dtype)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6a94ac12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[66., 56.],\n",
       "        [56., 49.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Syntax\n",
    "X[:,1]\n",
    "10 * (X+1)\n",
    "X.exp() #item-wise exponential\n",
    "X.mean(dim=0) # col-wise mean\n",
    "X @ X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "91f101ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 7.],\n",
       "        [2., 3., 6.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "torch.tensor(X.numpy(), dtype=torch.float32)\n",
    "# you can convert btwn numpy and torch easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9c85c294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., 99.,  7.],\n",
       "        [ 2., 99.,  6.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can modify in place\n",
    "X[:,1] = 99\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c3049dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0., 99.,  7.],\n",
       "        [ 0., 99.,  6.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,0] = -5\n",
    "X.relu_() \n",
    "# Methods ending in _ are in place, normal methods are not in place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c720f7",
   "metadata": {},
   "source": [
    "### Hardware Acceleration\n",
    "\n",
    "PyTorch has accelerator support for intel, apple, nvidia, amd, etc etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac47a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a gpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"We have a gpu\")\n",
    "\n",
    "M = torch.tensor([[1,2,3],[4,5,6]], dtype=torch.float32)\n",
    "M = M.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9292fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.device\n",
    "# There are multiple ways to put tensors on gpus, like .cuda(), or setting device= param in torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5300cf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14., 32.],\n",
       "        [32., 77.]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = M @ M.T\n",
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17660ac3",
   "metadata": {},
   "source": [
    "If your neural net is deep, GPU speed and RAM matters most, if its shallow, getting training data onto GPU is the bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d0e893b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.5 ms ± 742 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "M = torch.rand((1000,1000))\n",
    "%timeit M @ M.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee3d1189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560 µs ± 12.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "M = torch.rand((1000,1000), device=\"cuda\")\n",
    "%timeit M @ M.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8db1fc",
   "metadata": {},
   "source": [
    "### Autograd\n",
    "\n",
    "PyTorch does reverse-mode auto-diff (ch9) quickly with a method called autograd (auto gradients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3411b4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(5.0, requires_grad=True) # requires_grad tells pytorch to keep track of computations for backpropagation\n",
    "f = x**2 # keeps a grad_fn= argument to tell pytorch how to backpropagate through this\n",
    "f.backward() # computes gradients\n",
    "x.grad\n",
    "# the derivative of x**2 at x=5 is in fact 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3217e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do gradient descent, you need to tell pytorch not to track this step\n",
    "# Otherwise it would include it in backprop\n",
    "\n",
    "lr = .1\n",
    "with torch.no_grad():\n",
    "    x -= lr*x.grad\n",
    "\n",
    "# This code is equivalent: (x detached shares memory with x)\n",
    "# x_detached = x.detach()\n",
    "# x_detached -= lr*x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e3bcfb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before you repeat the forward > backward > gradient descent step, need to set gradients to 0\n",
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1038ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8026e-45, requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The whole training loop:\n",
    "lr = .1\n",
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "for i in range(500):\n",
    "    f = x**2\n",
    "    f.backward()\n",
    "    with torch.no_grad():\n",
    "        x -= lr*x.grad\n",
    "    x.grad.zero_()\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7385a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use in-place operations to save memory you have to be careful\n",
    "# Autograd doesnt let you do an in-place op to a leaf node\n",
    "\n",
    "t = torch.tensor(2.0, requires_grad=True)\n",
    "Z = t.exp() # intermediate step\n",
    "Z+=1 # in place operation (pytorch has no idea where to keep the computation graph for both steps)\n",
    "# Z.backward() #-> throws error\n",
    "\n",
    "# you need to do Z = Z+1, it creates a new step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a8342",
   "metadata": {},
   "source": [
    "PyTorch stores different operations differently\n",
    "- exp(), relu(), sqrt(), sigmoid(), tanh() save output in computation graph during the forward pass. You cannot modify their output in place.\n",
    "- abs(), cos(), log() save their inputs, so you cant change whatever you input to them before the backward pass\n",
    "- max(), min(), sgn(), std() save inputs and outputs, so do not change their inputs or outputs in place before .backward()\n",
    "- ceil(), floor(), mean(), sum() store nothing. Do what you want\n",
    "\n",
    "Generally, make your models without in-place ops, then if you need to speed up or save memory you can convert to in-place operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004dce5f",
   "metadata": {},
   "source": [
    "## Implementing Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3de74844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = fetch_california_housing(as_frame=False)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(data.data, data.target, test_size=.2)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02090d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_valid = torch.FloatTensor(X_valid)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "means = X_train.mean(dim=0, keepdims=True)\n",
    "stds = X_train.std(dim=0, keepdims=True)\n",
    "# stdizing\n",
    "X_train = (X_train-means)/stds\n",
    "X_valid = (X_valid-means)/stds\n",
    "X_test = (X_test-means)/stds\n",
    "\n",
    "y_train = torch.FloatTensor(y_train).reshape(-1,1)\n",
    "y_valid = torch.FloatTensor(y_valid).reshape(-1,1)\n",
    "y_test = torch.FloatTensor(y_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55f63121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 16.10413360595703\n",
      "Epoch 1 loss: 4.7485222816467285\n",
      "Epoch 2 loss: 2.1557693481445312\n",
      "Epoch 3 loss: 1.2681255340576172\n",
      "Epoch 4 loss: 0.9314724206924438\n",
      "Epoch 5 loss: 0.7929383516311646\n",
      "Epoch 6 loss: 0.7285262942314148\n",
      "Epoch 7 loss: 0.6930748224258423\n",
      "Epoch 8 loss: 0.6697714328765869\n",
      "Epoch 9 loss: 0.6522001624107361\n",
      "Epoch 10 loss: 0.637814462184906\n",
      "Epoch 11 loss: 0.6255297064781189\n",
      "Epoch 12 loss: 0.6148261427879333\n",
      "Epoch 13 loss: 0.6054105162620544\n",
      "Epoch 14 loss: 0.5970878601074219\n",
      "Epoch 15 loss: 0.5897108316421509\n",
      "Epoch 16 loss: 0.5831598043441772\n",
      "Epoch 17 loss: 0.5773330926895142\n",
      "Epoch 18 loss: 0.5721437335014343\n",
      "Epoch 19 loss: 0.5675159096717834\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "n = X_train.shape[1] # n features\n",
    "w = torch.randn((n,1), requires_grad=True) # weights\n",
    "b = torch.tensor(0., requires_grad=True) # biases\n",
    "\n",
    "lr = .4\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_pred = X_train @ w + b\n",
    "    loss = ((y_pred - y_train) ** 2).mean()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        b -= b.grad * lr\n",
    "        w -= w.grad * lr\n",
    "        b.grad.zero_()\n",
    "        w.grad.zero_()\n",
    "    print(f\"Epoch {epoch} loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "288d10a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3698],\n",
      "        [3.1893],\n",
      "        [4.4496]])\n"
     ]
    }
   ],
   "source": [
    "# Making predictions\n",
    "with torch.no_grad():\n",
    "    print(X_test[:3] @ w + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9179ee4c",
   "metadata": {},
   "source": [
    "This works but PyTorch has a higher level API to do all this easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d3881",
   "metadata": {},
   "source": [
    "#### PyTorch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1f594b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = nn.Linear(in_features=n, out_features=1)\n",
    "model.weight #.weight and .bias are children of torch.nn.Parameter, which is a child of torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc0a7cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3117], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2919933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4163]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train[:1])\n",
    "# not trained yet so predictions r random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bb5f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to pick an optimizier and a loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "def train_bgd(model, optimizer, criterion, X_train, y_train, n_epochs):\n",
    "    tenth = n_epochs //10\n",
    "    for epoch in range(n_epochs):\n",
    "        yPred = model(X_train)\n",
    "        loss = criterion(y_train, yPred)\n",
    "        loss.backward()\n",
    "        optimizer.step() # updates b, w\n",
    "        optimizer.zero_grad()\n",
    "        if(epoch % tenth == 0):\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51a9d803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 4.3149943351745605\n",
      "Epoch 20, Loss: 0.5357152223587036\n",
      "Epoch 40, Loss: 0.5262251496315002\n",
      "Epoch 60, Loss: 0.524800181388855\n",
      "Epoch 80, Loss: 0.5245195627212524\n",
      "Epoch 100, Loss: 0.5244590640068054\n",
      "Epoch 120, Loss: 0.524445652961731\n",
      "Epoch 140, Loss: 0.5244426131248474\n",
      "Epoch 160, Loss: 0.5244419574737549\n",
      "Epoch 180, Loss: 0.5244418382644653\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "train_bgd(model, optimizer, mse, X_train, y_train, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "069b90e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3073],\n",
       "        [3.3351],\n",
       "        [4.2830]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_new)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7941fd08",
   "metadata": {},
   "source": [
    "## Implementing a Regression MLP\n",
    "\n",
    "pytorch has `nn.Sequential` that lets you chain modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d431621",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(n, 50), # n inputs and any number of outputs\n",
    "    nn.ReLU(), # shape of output = shape input. just an activation function\n",
    "    nn.Linear(50,40), # inputs of 2 must equal outputs of 1. number of outputs can be whatever you want though\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40,1) # final n outputs must match targets dimension\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac05af5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 5.926211833953857\n",
      "Epoch 100, Loss: 0.526648998260498\n",
      "Epoch 200, Loss: 0.45027604699134827\n",
      "Epoch 300, Loss: 0.4206412136554718\n",
      "Epoch 400, Loss: 0.4043380916118622\n",
      "Epoch 500, Loss: 0.3916199207305908\n",
      "Epoch 600, Loss: 0.38045424222946167\n",
      "Epoch 700, Loss: 0.37107452750205994\n",
      "Epoch 800, Loss: 0.3623618185520172\n",
      "Epoch 900, Loss: 0.354219526052475\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "\n",
    "train_bgd(model, optimizer, mse, X_train, y_train, 1000)\n",
    "print(next(model.parameters()).device) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d19ae8",
   "metadata": {},
   "source": [
    "## Mini-Batch Gradient Descent w/ DataLoaders\n",
    "\n",
    "Torch has a `torch.utils.data.DataLoader` class that efficiently loads data and shuffles if we want it to\n",
    "\n",
    "DataLoaders expects the dataset to have a len() and getitem() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "961423f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n, 50), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(50,40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40,1) \n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63f156f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, n_epochs):\n",
    "    model.train() # this switched modules to training mode, doesnt matter rn but it will later\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_batch, y_pred)\n",
    "            total_loss+=loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {mean_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6e3b0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: nan\n",
      "Epoch 2/20, Loss: nan\n",
      "Epoch 3/20, Loss: nan\n",
      "Epoch 4/20, Loss: nan\n",
      "Epoch 5/20, Loss: nan\n",
      "Epoch 6/20, Loss: nan\n",
      "Epoch 7/20, Loss: nan\n",
      "Epoch 8/20, Loss: nan\n",
      "Epoch 9/20, Loss: nan\n",
      "Epoch 10/20, Loss: nan\n",
      "Epoch 11/20, Loss: nan\n",
      "Epoch 12/20, Loss: nan\n",
      "Epoch 13/20, Loss: nan\n",
      "Epoch 14/20, Loss: nan\n",
      "Epoch 15/20, Loss: nan\n",
      "Epoch 16/20, Loss: nan\n",
      "Epoch 17/20, Loss: nan\n",
      "Epoch 18/20, Loss: nan\n",
      "Epoch 19/20, Loss: nan\n",
      "Epoch 20/20, Loss: nan\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, mse, train_loader, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41425fb",
   "metadata": {},
   "source": [
    "- You can set `pin_memory=True` in the dataloader to speed up training and the cost of more cpu ram\n",
    "    - Also set `non_blocking=True` in the .to() method to avoid blocking cpu during data transfer\n",
    "\n",
    "- This training loop waits until one batch is done to load another. Set dataloaders `num_workers=` to add workers, and tweak number of batches fetched with `prefetch_factor`. Windows sometimes lags with this, so set `persistent_workers=True` to reuse workers \n",
    "\n",
    "- Note that it seems like these arguments have issues in juypter notebook and you might have to work in .py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25925978",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02638849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, metric_fn, aggregate_fn=torch.mean):\n",
    "    model.eval()\n",
    "    metrics=[]\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            metric = metric_fn(y_pred, y_batch)\n",
    "            metrics.append(metric)\n",
    "    return aggregate_fn(torch.stack(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "119fcc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set = TensorDataset(X_valid, y_valid)\n",
    "valid_loader = DataLoader(valid_set, batch_size=32)\n",
    "valid_mse = evaluate(model, valid_loader, mse)\n",
    "valid_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc4493c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to use rmse\n",
    "def rmse(pred, true):\n",
    "    return ((pred-true)**2).mean().sqrt()\n",
    "\n",
    "evaluate(model, valid_loader, rmse)\n",
    "\n",
    "# root(mse) != rmse because torch computed the mean rmse across sets, not the root of total mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c806d422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, valid_loader, mse, aggregate_fn=lambda metrics: torch.sqrt(torch.mean(metrics)))\n",
    "# Use MSE as metric function, and aggregate by taking the root of the mean mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f1311",
   "metadata": {},
   "source": [
    "## Nonsequential Models w/ Custom Modules\n",
    "\n",
    "Wide and Deep neural net: all/part of inputs are connected directly to the output layer, letting the model learn shallow and deep patterns\n",
    "\n",
    "We need to use `nn.Module` to build our custom network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27101c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeep(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.deep_stack = nn.Sequential(\n",
    "            nn.Linear(n_features, 50), nn.ReLU(),\n",
    "            nn.Linear(50,40), nn.ReLU(),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(40+n_features, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        deep_output = self.deep_stack(X)\n",
    "        wide_and_deep = torch.concat([X, deep_output], dim=1)\n",
    "        return self.output_layer(wide_and_deep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9be38e",
   "metadata": {},
   "source": [
    "Modules have a .children() method that lets you iterate over the submodules. If your model has a changing number of submodules, you should store them in an nn.ModuleList, and if you have a changing number of params, you should keep it in a nn.ParameterList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d68e953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.4733\n",
      "Epoch 2/20, Loss: 0.6642\n",
      "Epoch 3/20, Loss: 0.5963\n",
      "Epoch 4/20, Loss: 0.5630\n",
      "Epoch 5/20, Loss: 0.5397\n",
      "Epoch 6/20, Loss: 0.5259\n",
      "Epoch 7/20, Loss: 0.5143\n",
      "Epoch 8/20, Loss: 0.5062\n",
      "Epoch 9/20, Loss: 0.4983\n",
      "Epoch 10/20, Loss: 0.4910\n",
      "Epoch 11/20, Loss: 0.4866\n",
      "Epoch 12/20, Loss: 0.4773\n",
      "Epoch 13/20, Loss: 0.4719\n",
      "Epoch 14/20, Loss: 0.4653\n",
      "Epoch 15/20, Loss: 0.4612\n",
      "Epoch 16/20, Loss: 0.4563\n",
      "Epoch 17/20, Loss: 0.4504\n",
      "Epoch 18/20, Loss: 0.4441\n",
      "Epoch 19/20, Loss: 0.4402\n",
      "Epoch 20/20, Loss: 0.4345\n"
     ]
    }
   ],
   "source": [
    "model = WideAndDeep(n).to(device)\n",
    "lr = .002\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "train(model, optimizer, mse, train_loader, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f713172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to send a subset of the features thru the wide path, and a different (mayb overlapping) part through the deep path, you can do smthn likethis:\n",
    "class WideAndDeep2(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.deep_stack = nn.Sequential(\n",
    "            nn.Linear(n_features, 50), nn.ReLU(),\n",
    "            nn.Linear(50,40), nn.ReLU(),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(40+n_features, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X_wide = X[:, :5]\n",
    "        X_deep = X[:, 2:]\n",
    "        deep_output = self.deep_stack(X_deep)\n",
    "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
    "        return self.output_layer(wide_and_deep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c9bc72",
   "metadata": {},
   "source": [
    "### Making Models with Multiple Inputs\n",
    "\n",
    "Its usually better to just let the model take two tensors as input rather than trying to data split within the model. (like images + text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a87c9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeep3(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.deep_stack = nn.Sequential(\n",
    "            nn.Linear(n_features, 50), nn.ReLU(),\n",
    "            nn.Linear(50,40), nn.ReLU(),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(40+n_features, 1)\n",
    "\n",
    "    def forward(self, X_wide, X_deep):\n",
    "        deep_output = self.deep_stack(X_deep)\n",
    "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
    "        return self.output_layer(wide_and_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b6a519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(X_train[:, :5], X_train[:, 2:], y_train)\n",
    "train_loader_wd = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# you need to make sure your train and eval functions handle 3 tensors\n",
    "def evaluate(model, data_loader, metric_fn, aggregate_fn=torch.mean):\n",
    "    model.eval()\n",
    "    metrics=[]\n",
    "    with torch.no_grad():\n",
    "        for X_batch_wide, X_batch_deep, y_batch in data_loader:\n",
    "            X_batch_wide = X_batch_wide.to(device)\n",
    "            X_batch_deep = X_batch_deep.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred = model(X_batch_wide, X_batch_deep)\n",
    "            metric = metric_fn(y_pred, y_batch)\n",
    "            metrics.append(metric)\n",
    "    return aggregate_fn(torch.stack(metrics))\n",
    "\n",
    "def train(model, optimizer, criterion, train_loader, n_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.0\n",
    "        for X_batch_wide, X_batch_deep, y_batch in train_loader:\n",
    "            X_batch_wide = X_batch_wide.to(device)\n",
    "            X_batch_deep = X_batch_deep.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred = model(X_batch_wide, X_batch_deep)\n",
    "            loss = criterion(y_batch, y_pred)\n",
    "            total_loss+=loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {mean_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ec674af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IFF your inputs are in the same order everywhere, you can use something like this: \n",
    "\n",
    "# for *X_batch_inputs, y_batch in data_loader:\n",
    "#     X_batch_inputs = [X.to(device) for X in X_batch_inputs]\n",
    "#     y_batch = y_batch.to(device)\n",
    "#     y_pred = model(*X_batch_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b98c359",
   "metadata": {},
   "source": [
    "If your model has a lot of inputs, it can be easy to mess up the order. You can make a custom dataset this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050588fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_wide, X_deep, y):\n",
    "        self.X_wide = X_wide\n",
    "        self.X_deep = X_deep\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_dict = {\"X_wide\": self.X_wide[idx], \"X_deep\": self.X_deep[idx]}\n",
    "        return input_dict, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af285ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_named = WideAndDeepDataset(\n",
    "                    X_wide = X_train[:,:5], \n",
    "                    X_deep = X_train[:,2:], \n",
    "                    y=y_train)\n",
    "train_loader_named = DataLoader(train_data_named, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dfa214bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update your train and eval with this chunk:\n",
    "\n",
    "# for inputs, y_batch in data_loader:\n",
    "#     inputs = {name: X.to(device)for name, X in inputs.items()}\n",
    "#     y_batch = y_batch.to(device)\n",
    "#     y_pred = model(X_wide=inputs[\"X_wide\"], X_deep=inputs[\"X_deep\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec60f75",
   "metadata": {},
   "source": [
    "### Models w/ Multiple Outputs\n",
    "\n",
    "example problems:\n",
    "- Locate and classify object in an image (regression + classifications)\n",
    "- Multiple independent tasks based on the same data (is someone smiling, are they wearing glasses)\n",
    "- Regularization (forcing one part of the network to learn something on its own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6880633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeep4(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.deep_stack = nn.Sequential(\n",
    "            nn.Linear(n_features, 50), nn.ReLU(),\n",
    "            nn.Linear(50,40), nn.ReLU(),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(40+n_features, 1)\n",
    "        self.aux_output_layer = nn.Linear(40,1)\n",
    "\n",
    "    def forward(self, X_wide, X_deep):\n",
    "        deep_output = self.deep_stack(X_deep)\n",
    "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
    "        main_output = self.output_layer(wide_and_deep)\n",
    "        aux_output = self.aux_output_layer(deep_output)\n",
    "        return \n",
    "    \n",
    "# need to modify training function too\n",
    "\n",
    "def train(model, optimizer, criterion, train_loader, n_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.0\n",
    "        for inputs, y_batch in train_loader:\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred, y_pred_aux = model(**inputs)\n",
    "            main_loss = criterion(y_pred, y_batch)\n",
    "            aux_loss = criterion(y_pred_aux, y_batch)\n",
    "            loss = 0.8 * main_loss + 0.2 * aux_loss # you can fine tune the ratio\n",
    "            total_loss+=loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "def evaluate(model, data_loader, metric_fn, aggregate_fn=torch.mean):\n",
    "    model.eval()\n",
    "    metrics=[]\n",
    "    with torch.no_grad():\n",
    "        for inputs, y_batch in data_loader:\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred, _ = model(**inputs)\n",
    "            metric = metric_fn(y_pred, y_batch)\n",
    "            metrics.append(metric)\n",
    "    return aggregate_fn(torch.stack(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edc5b29",
   "metadata": {},
   "source": [
    "## Image Classifier in PyTorch\n",
    "\n",
    "TorchVision has a lot of tools for computer vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1eb2a2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:01<00:00, 13.3MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 212kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.93MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 13.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms.v2 as T\n",
    "\n",
    "toTensor = T.Compose([T.ToImage(), T.ToDtype(torch.float32, scale=True)]) #scales 0-1\n",
    "# by default, fashionmnist loads PIL images, but we need pytorch float tensors\n",
    "# you can transform data by specifying a transform argument in the dataset call\n",
    "train_and_valid_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"datasets\", train=True, download=True, transform=toTensor\n",
    ")\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"datasets\", train=False, download=True, transform=toTensor\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_data, valid_data = torch.utils.data.random_split(\n",
    "    train_and_valid_data, [55000, 5000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "278e2fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=32)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "X_sample, y_sample = train_data[0]\n",
    "X_sample.shape\n",
    "# first dim is channel dimension, for greyscale its just 1 channel, rgb has 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "028791e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_valid_data.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d0b24",
   "metadata": {},
   "source": [
    "### Building the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43974a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden1, n_hidden2, n_classes):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Flatten(), # reshapes each input to single dimension\n",
    "            nn.Linear(n_inputs, n_hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden1, n_hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden2, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.mlp(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11664c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageClassifier(n_inputs=28*28, n_hidden1=300, n_hidden2=100, n_classes=10)\n",
    "xentropy = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b7c837",
   "metadata": {},
   "source": [
    "We dont need softmax to give class probabilities, pytorch crossentropyloss can work directly with logits rather than probas (more efficient)\n",
    "\n",
    "But then we need to manually compute probas if we want them\n",
    "\n",
    "For binary classification, one output, and use `nn.BCEWithLogitsLoss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d210e14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cu126)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
      "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n",
      "Epoch: 0 - Loss: 2.067446428513097\n",
      "Epoch: 1 - Loss: 1.2289777294780848\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics\n",
    "import torchmetrics\n",
    "device = \"cuda\"\n",
    "\n",
    "def train(model, optimizer, criterion, train_loader, n_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.0\n",
    "        for inputs, y_batch in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred = model(inputs)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print(f\"Epoch: {epoch} - Loss: {total_loss/len(train_loader)}\")\n",
    "\n",
    "def evaluate(model, data_loader, metric_fn, aggregate_fn=torch.mean):\n",
    "    model.eval()\n",
    "    metrics=[]\n",
    "    with torch.no_grad():\n",
    "        for inputs, y_batch in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred = model(inputs)\n",
    "            metric = metric_fn(y_pred, y_batch)\n",
    "            metrics.append(metric)\n",
    "    return aggregate_fn(torch.stack(metrics))\n",
    "\n",
    "model = model.to(\"cuda\")\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "train(model, optimizer, xentropy, train_loader, 2)\n",
    "# training is slow so make epochs > 5 if you really want to train this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3caf404d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sneaker', 'Coat', 'Coat']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing predictions\n",
    "iter = __builtins__.iter\n",
    "\n",
    "model.eval()\n",
    "X_new, y_new = next(iter(valid_loader))\n",
    "X_new = X_new[:3].to(device)\n",
    "with torch.no_grad():\n",
    "    y_pred_logits = model(X_new)\n",
    "\n",
    "y_pred = y_pred_logits.argmax(dim=1)\n",
    "[train_and_valid_data.classes[index] for index in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd3be799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0020, 0.0020, 0.0090, 0.0030, 0.0050, 0.2260, 0.0050, 0.5580, 0.0690,\n",
       "        0.1210], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting predicted probas\n",
    "import torch.nn.functional as F\n",
    "\n",
    "F.softmax(y_pred_logits, dim=1).round(decimals=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "870fbfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5730, 0.2330, 0.1240, 0.0710],\n",
       "        [0.4800, 0.3040, 0.1670, 0.0500],\n",
       "        [0.3540, 0.3190, 0.2170, 0.1100]], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get top k predictions\n",
    "y_top4_logits, y_top4_idx = torch.topk(y_pred_logits, k=4, dim=1)\n",
    "y_top4_probas = F.softmax(y_top4_logits, dim=1)\n",
    "y_top4_probas.round(decimals=3)\n",
    "# y_top4_idx has idx of each proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d9691b",
   "metadata": {},
   "source": [
    "For unbalanced datasets (n instances per class not equal), you should set `weight` in `nn.CrossEntropyLoss` to a vector containing each classes weight, where weight is total_instances / class_instances (scaled to 0-1), so smaller classes have a greater weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d68283",
   "metadata": {},
   "source": [
    "## Fine-Tuning Neural Nets with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c6df197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.7.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.18.1)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.46)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
      "Downloading optuna-4.7.0-py3-none-any.whl (413 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.9/413.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: colorlog, optuna\n",
      "Successfully installed colorlog-6.10.1 optuna-4.7.0\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f48735d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    n_hidden = trial.suggest_int(\"n_hidden\", 20, 300)\n",
    "    model = ImageClassifier(n_inputs=1*28*28, n_hidden1=n_hidden, n_hidden2=n_hidden, n_classes=10).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    xentropy = nn.CrossEntropyLoss()\n",
    "    train(model, optimizer, xentropy, train_loader, 1)\n",
    "    v = evaluate(model, valid_loader, xentropy)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4634f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-02 01:19:26,380] A new study created in memory with name: no-name-7cd68fd8-e096-4383-b27b-6bd448ebfe52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Loss: 2.270235518787821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-02 01:19:42,986] Trial 0 finished with value: 2.2352724075317383 and parameters: {'learning_rate': 0.00031489116479568613, 'n_hidden': 287}. Best is trial 0 with value: 2.2352724075317383.\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64747c12",
   "metadata": {},
   "source": [
    "suggest_float and suggst_int ask optuna for good params, and for learning rate we specify to sample from log scale to get low values more often\n",
    "\n",
    "The objective function returns a score, higher is better, so we have to set direction in create study to maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db76bfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.00031489116479568613, 'n_hidden': 287}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params\n",
    "# study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb9287",
   "metadata": {},
   "source": [
    "Generally its better to pass youe dataloaders into the objective function as an argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b41e1b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Loss: 1.1457130481261997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-02 01:19:59,612] Trial 1 finished with value: 0.7096635103225708 and parameters: {'learning_rate': 0.008471801418819975, 'n_hidden': 188}. Best is trial 0 with value: 2.2352724075317383.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, train_loader, valid_loader):\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    n_hidden = trial.suggest_int(\"n_hidden\", 20, 300)\n",
    "    model = ImageClassifier(n_inputs=1*28*28, n_hidden1=n_hidden, n_hidden2=n_hidden, n_classes=10).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    xentropy = nn.CrossEntropyLoss()\n",
    "    train(model, optimizer, xentropy, train_loader, 1)\n",
    "    v = evaluate(model, valid_loader, xentropy)\n",
    "    return v\n",
    "\n",
    "objective_with_data = lambda trial: objective(\n",
    "    trial, train_loader=train_loader, valid_loader=valid_loader)\n",
    "study.optimize(objective_with_data, n_trials=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c2d073",
   "metadata": {},
   "source": [
    "You can make a pruner to get rid of bad trials instead of wasting compute on them\n",
    "\n",
    "MedianPruner args:\n",
    "- n_startup_trials: trials until pruning starts\n",
    "- n_warmup_steps: epochs until pruning starts (after startup trials)\n",
    "- interval_steps: how many epochs between checks for pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7f60729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-02 01:19:59,677] A new study created in memory with name: no-name-be08838d-fc3a-446b-b94b-dcb2e60c2f87\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=0, interval_steps=1)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler, pruner=pruner)\n",
    "\n",
    "n_epochs=1\n",
    "# adjust the objective function like so:\n",
    "def objective(trial, train_loader, valid_loader):\n",
    "    for epoch in range(n_epochs):\n",
    "        lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "        n_hidden = trial.suggest_int(\"n_hidden\", 20, 300)\n",
    "        model = ImageClassifier(n_inputs=1*28*28, n_hidden1=n_hidden, n_hidden2=n_hidden, n_classes=10).to(device)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "        xentropy = nn.CrossEntropyLoss()\n",
    "        train(model, optimizer, xentropy, train_loader, 1)\n",
    "        v = evaluate(model, valid_loader, xentropy)\n",
    "        trial.report(v, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3a11e8",
   "metadata": {},
   "source": [
    "## Saving and Loading PyTorch Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bf391f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplest way:\n",
    "torch.save(model, \"my_model.pt\")\n",
    "\n",
    "# load:\n",
    "loaded_model = torch.load(\"my_model.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e32042",
   "metadata": {},
   "source": [
    "You must keep custom classes/functions when loading a saved model, because the saved model only stores references, not the functions themselves\n",
    "\n",
    "Setting weights_only meansyou get the whole model, not just weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c87307e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0883, -2.2779, -0.6950, -1.6345, -1.1914,  2.5527, -1.3021,  3.4541,\n",
       "          1.3635,  1.9228],\n",
       "        [ 1.2032, -2.2533,  3.9686,  0.2705,  4.4270, -2.0547,  3.3680, -4.3984,\n",
       "          2.1554, -2.1012],\n",
       "        [ 1.2739, -2.9186,  3.5424, -0.1503,  3.6466, -1.5096,  3.1561, -3.6141,\n",
       "          2.4764, -1.5193]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.eval()\n",
    "loaded_model(X_new) # make prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976267ea",
   "metadata": {},
   "source": [
    "There are some issues with this method:\n",
    "- pickle (the engine behind torch.save()) supports custom code, so someone could put anything in a .pt model you load (malware)\n",
    "- pickle can break if theres filepath changes to locate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc45b09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to avoid this, only save and load weights\n",
    "torch.save(model.state_dict(), \"weights.pt\")\n",
    "\n",
    "# state_dict() returns all params + buffers (see ch11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b7575183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifier(\n",
       "  (mlp): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to use the weights, need to create an identical model and manually set weights\n",
    "\n",
    "new_model = ImageClassifier(n_inputs=28*28, n_hidden1=300, n_hidden2=100, n_classes=10)\n",
    "weights = torch.load(\"weights.pt\", weights_only=True)\n",
    "new_model.load_state_dict(weights)\n",
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d2638970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifier(\n",
       "  (mlp): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Its a good idea to pass the hyperparameters through as well\n",
    "\n",
    "model_data = {\n",
    "    \"model_hyperparameters\": {\"n_inputs\":28*28, \"n_hidden1\":300, \"n_hidden2\":100, \"n_classes\":10},\n",
    "    \"model_state_dict\": model.state_dict()\n",
    "}\n",
    "torch.save(model_data, \"weights.pt\")\n",
    "\n",
    "# you can rebuild like this\n",
    "\n",
    "loaded_data = torch.load(\"weights.pt\", weights_only=True)\n",
    "new_model = ImageClassifier(**loaded_data[\"model_hyperparameters\"])\n",
    "new_model.load_state_dict(loaded_data[\"model_state_dict\"])\n",
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b94da3",
   "metadata": {},
   "source": [
    "to stop in the middle of training, save, load, then restart training, you have to save the optimizers state dict and hyperparams + epoch/loss info if you need.\n",
    "\n",
    "HuggingFace's `safetensors` and TorchScript are also ways to save models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c0143",
   "metadata": {},
   "source": [
    "## Compiling and Optimizing a PyTorch Model\n",
    "\n",
    "PyTorch can automatically convert model code to TorchScript, improves speed by fusing operations with constants (constant folding)\n",
    "\n",
    "TorchScript can be serialized, saved to disk, loaded+executed in python or c++ with LibTorch, making running pytorch possible on lots of devices\n",
    "\n",
    "2 ways to convert model to TorchScript\n",
    "\n",
    "1: **tracing**\n",
    "\n",
    "- PyTorch runs your model with sample data, logs every operation, and converts this log to torchscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "30209d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracing\n",
    "torchscript_model = torch.jit.trace(model, X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e34d278",
   "metadata": {},
   "source": [
    "This works good for static models, whose .forward() doesnt depend on conditionals or loops\n",
    "\n",
    "If you have if/match statement only the one that gets executed will be saved by TorchScript\n",
    "\n",
    "2nd method: **scripting**\n",
    "\n",
    "- pytorch parses your code directly and makes it into torchscript\n",
    "- this works with if/while, as long as the conditions are tensors\n",
    "- only works on a subset of python: no global vars, no generators, no variable length function arguments, types must be fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "043fdaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(original_name=ImageClassifier)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchscript_model = torch.jit.script(model)\n",
    "optimized = torch.jit.optimize_for_inference(torchscript_model)\n",
    "optimized.save(\"weights.pt\")\n",
    "torch.jit.load(\"weights.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed2f43f",
   "metadata": {},
   "source": [
    "You can optimize torchscript models for inference regarless of if you script or trace, then save and load them.\n",
    "\n",
    "TorchScript has stopped being updated, and now the pytorch team focuses on .compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9aa9e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09d2bb5",
   "metadata": {},
   "source": [
    "This can be used normally, and itll automatically compile and be optimized when you use it.\n",
    "\n",
    "Relies on looking at python bytecode to grab conditionals, loops, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4ed715",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. PyTorch features vs numpy: Autograd, DataLoaders, saving models, lots of activation functions\n",
    "    - Also hardware acceleration\n",
    "2. exp() vs exp_() : Not in place vs in place operations\n",
    "3. Making tensor on gpu: You can specify the device in the tensor declaration or use its .to() method\n",
    "4. Tensor ops without autograd: with torch.no_grad(),\n",
    "    - Specify requires_grad = False or .detach()\n",
    "5. I don't think you can run in place operations on this because youre calling .backward()\n",
    "    - Not true. You can call .exp_() last since the derivative of exp(x) is exp(x). You cannot call cos_() last since its derivative is -sin\n",
    "6. Linear(100,200) module. Neurons: 200. Weight is 100x200 matrix, bias is 200x1 matrix. Expects z x 100 input. Produces z x 200 output.\n",
    "    - Weight is actually 200x100.\n",
    "7. Training loop steps: Dataloader, optimizer, training call, forward pass, backward, gradient descent, zero_grad().\n",
    "    - Sample batch > to gpu, forward pass, loss, backward, optimizer step, zero grad.\n",
    "8. Why create optimizer after model is on gpu: \n",
    "    - Most optimizers have some internal sttae, and this state is on the same device as model params\n",
    "9. pin_memory, num_workers, prefetch_factor\n",
    "10. Cross Entropy Loss, BCELoss, BCEWithLogitsLoss. BCE/BCEWithLogits is for binary classification, cross entropy is for multiclass.\n",
    "11. Call model.train() and model.eval() because some layers dont behave in the same way during training and eval\n",
    "    - nn.Dropout, nn.BatchNorm**\n",
    "12. trace doesnt work with conditionals in forward, script does\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a21a0136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4899, 0.2629])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.2, 3.4], requires_grad=True)\n",
    "f = torch.sin(x[0]**2 * x[1])\n",
    "f.backward()\n",
    "x.grad\n",
    "\n",
    "# you can also define the inputs in separate tensors and get the same result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
