{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca32bc9",
   "metadata": {},
   "source": [
    "# Better Housing Regression w/ Ensemble Models\n",
    "\n",
    "Data from https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data\n",
    "\n",
    "Goal: beat the basic regression done in HousingRegression.ipynb. \n",
    "\n",
    "Score to beat: .14834 (lower is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f6ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "89d46241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "trainData = pd.read_csv(\"datasets/train.csv\")\n",
    "submissionData = pd.read_csv(\"datasets/test.csv\")\n",
    "\n",
    "yvals = trainData[\"SalePrice\"].copy()\n",
    "xvals = trainData.drop(columns=\"SalePrice\")\n",
    "price_bins = pd.qcut(yvals, q=8)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(xvals, yvals, test_size=.15, stratify=price_bins)\n",
    "\n",
    "ytrainLog = np.log1p(ytrain)\n",
    "ytestLog = np.log1p(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521417e3",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7df7e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformX(df):\n",
    "    df[\"TotalSF\"] = df[\"GrLivArea\"] + df[\"TotalBsmtSF\"]\n",
    "    df[\"QualityArea\"] = df[\"OverallQual\"] * df[\"TotalSF\"]\n",
    "    df[\"TotalBath\"] = 0.5*df[\"HalfBath\"] + df[\"FullBath\"] + df[\"BsmtFullBath\"] + 0.5*df[\"BsmtHalfBath\"]\n",
    "    df[\"QualityScore\"] = df[\"OverallQual\"] * df[\"OverallCond\"]\n",
    "    df[\"BasementRatio\"] = df[\"TotalBsmtSF\"] / (df[\"GrLivArea\"]+1)\n",
    "    df[\"LivingSpaceRatio\"] = df[\"GrLivArea\"] / (df[\"LotArea\"]+1)\n",
    "    #\n",
    "    df['HouseAge'] = df['YrSold'] - df['YearBuilt']\n",
    "    df['YearsSinceRemod'] = df['YrSold'] - df['YearRemodAdd']\n",
    "    # df['IsNew'] = (df['YearBuilt'] == df['YrSold']).astype(int)\n",
    "    df['ExterQualNum'] = df['ExterQual'].map({'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1}).fillna(0)\n",
    "    df['KitchenQualNum'] = df['KitchenQual'].map({'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1}).fillna(0)\n",
    "    df['BsmtFinishedRatio'] = (df['BsmtFinSF1'] + df['BsmtFinSF2']) / (df['TotalBsmtSF'] + 1)\n",
    "    df['BsmtFinishedRatio'] = df['BsmtFinishedRatio'].fillna(0)\n",
    "    df['TotalPorchSF'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['3SsnPorch'] + df['ScreenPorch']\n",
    "    df['TotalPorchSF'] = np.log1p(df['TotalPorchSF'])\n",
    "    #\n",
    "    df[\"TotalSF\"] = np.log1p(df[\"GrLivArea\"] + df[\"TotalBsmtSF\"])\n",
    "    df[\"LotArea\"] = np.log1p(df[\"LotArea\"])\n",
    "    df[\"MasVnrArea\"] = np.log1p(df[\"MasVnrArea\"])\n",
    "    df[\"BsmtFinSF1\"] = np.log1p(df[\"BsmtFinSF1\"])\n",
    "    df[\"BsmtFinSF2\"] = np.log1p(df[\"BsmtFinSF2\"])\n",
    "    df[\"BsmtUnfSF\"] = np.log1p(df[\"BsmtUnfSF\"])\n",
    "    df[\"TotalBsmtSF\"] = np.log1p(df[\"TotalBsmtSF\"])\n",
    "    df[\"1stFlrSF\"] = np.log1p(df[\"1stFlrSF\"])\n",
    "    df[\"2ndFlrSF\"] = np.log1p(df[\"2ndFlrSF\"])\n",
    "    df[\"LowQualFinSF\"] = np.log1p(df[\"LowQualFinSF\"])\n",
    "    df[\"GrLivArea\"] = np.log1p(df[\"GrLivArea\"])\n",
    "    df[\"GarageArea\"] = np.log1p(df[\"GarageArea\"])\n",
    "    df[\"WoodDeckSF\"] = np.log1p(df[\"WoodDeckSF\"])\n",
    "    df[\"OpenPorchSF\"] = np.log1p(df[\"OpenPorchSF\"])\n",
    "    df[\"EnclosedPorch\"] = np.log1p(df[\"EnclosedPorch\"])\n",
    "    df[\"WoodDeckSF\"] = np.log1p(df[\"WoodDeckSF\"])\n",
    "    df[\"WoodDeckSF\"] = np.log1p(df[\"WoodDeckSF\"])\n",
    "    df[\"WoodDeckSF\"] = np.log1p(df[\"WoodDeckSF\"])\n",
    "    df[\"WoodDeckSF\"] = np.log1p(df[\"WoodDeckSF\"])\n",
    "\n",
    "catVars = list(xtrain.select_dtypes(exclude=\"number\").columns)\n",
    "catVars.append(\"MSSubClass\")\n",
    "catVars.append(\"OverallQual\")\n",
    "catVars.append(\"OverallCond\")\n",
    "numVars = list(xtrain.select_dtypes(include=\"number\").drop(columns=[\"Id\", \"MSSubClass\", \"OverallQual\", \"OverallCond\"]).columns)\n",
    "catIndices = [xtrain.columns.get_loc(col) for col in catVars]\n",
    "numIndices = [xtrain.columns.get_loc(col) for col in numVars]\n",
    "\n",
    "xtrain.loc[:,numVars] = xtrain.loc[:,numVars].fillna(0)\n",
    "xtest.loc[:,numVars] = xtest.loc[:,numVars].fillna(0)\n",
    "\n",
    "transformX(xtrain)\n",
    "transformX(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18154003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "pipelineNoScaling = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), catIndices),\n",
    "    (\"num\", \"passthrough\", numIndices)\n",
    "])\n",
    "pipelineScaling = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), catIndices),\n",
    "    (\"num\", StandardScaler(), numIndices)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a76a3",
   "metadata": {},
   "source": [
    "### The Models\n",
    "\n",
    "1. Elastic Net -> the one built last time\n",
    "2. Bagging Regressor w/ Decision Trees\n",
    "3. Random Forest Regressor\n",
    "4. AdaBoost w/ Decision Trees\n",
    "5. Gradient Boosting\n",
    "6. CatBoost\n",
    "\n",
    "Lastly: use stacking to combine predictions from other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "041fc79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net Log-space RMSE: 0.13756133626812986\n",
      "Elastic Net Original-space RMSE: 28327.772211319247\n"
     ]
    }
   ],
   "source": [
    "# Elastic Net\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "netPipeline = Pipeline([\n",
    "    ('preprocessing', pipelineScaling),\n",
    "    ('model', ElasticNet())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__alpha': [0.01, 0.1, 1.0],\n",
    "    'model__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(netPipeline, param_grid, cv=10, \n",
    "                           scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(xtrain, ytrainLog)\n",
    "\n",
    "elasticNetModel = grid_search.best_estimator_\n",
    "\n",
    "predictionsLog = elasticNetModel.predict(xtest)\n",
    "logRMSE = np.sqrt(np.mean((predictionsLog - ytestLog)**2))\n",
    "print(f\"Elastic Net Log-space RMSE: {logRMSE}\")\n",
    "\n",
    "predictions = np.expm1(predictionsLog)\n",
    "originalRMSE = np.sqrt(np.mean((predictions - ytest)**2))\n",
    "print(f\"Elastic Net Original-space RMSE: {originalRMSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653a57c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Log-space RMSE: 0.17143849631484306\n",
      "Bagging Original-space RMSE: 33544.288032369994\n"
     ]
    }
   ],
   "source": [
    "# Bagging Regressor w/ Decision Trees\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Note: Grid Search was performed on each model to find good hyperparams. They are commented out to speed up notebook execution.\n",
    "\n",
    "# bagPipeline = Pipeline([\n",
    "#     ('preprocessing', pipelineNoScaling),\n",
    "#     ('model', DecisionTreeRegressor())\n",
    "# ])\n",
    "# param_grid = {\n",
    "#     'estimator__model__max_depth': [7, 10, 15, 20],\n",
    "#     'estimator__model__max_leaf_nodes': [64, 128, 256, 512],\n",
    "#     'estimator__model__min_samples_split': [5,10,20,50]\n",
    "# }\n",
    "# bagReg = BaggingRegressor(bagPipeline, n_jobs=-1, n_estimators=200, max_samples=.5)\n",
    "# randSearch = RandomizedSearchCV(bagReg, param_grid, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, n_iter=20)\n",
    "# randSearch.fit(xtrain,ytrainLog)\n",
    "# bagModel = randSearch.best_estimator_\n",
    "\n",
    "bagPipeline = Pipeline([\n",
    "    ('preprocessing', pipelineNoScaling),\n",
    "    ('model', DecisionTreeRegressor(max_depth=10, max_leaf_nodes=512, min_samples_split=15))\n",
    "])\n",
    "bagReg = BaggingRegressor(bagPipeline, n_jobs=-1, n_estimators=200, max_samples=.5)\n",
    "bagModel = bagReg.fit(xtrain,ytrainLog)\n",
    "\n",
    "predictionsLog = bagModel.predict(xtest)\n",
    "logRMSE = np.sqrt(np.mean((predictionsLog - ytestLog)**2))\n",
    "print(f\"Bagging Log-space RMSE: {logRMSE}\")\n",
    "\n",
    "predictions = np.expm1(predictionsLog)\n",
    "originalRMSE = np.sqrt(np.mean((predictions - ytest)**2))\n",
    "print(f\"Bagging Original-space RMSE: {originalRMSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eccad329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Log-space RMSE: 0.15740733156587194\n",
      "Random Forest Original-space RMSE: 30750.378467089464\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor\n",
    "from numpy.core.umath import maximum\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# rfPipeline = Pipeline([\n",
    "#     ('preprocessing', pipelineNoScaling),\n",
    "#     ('model', RandomForestRegressor(n_estimators=200))\n",
    "# ])\n",
    "# param_grid = {\n",
    "#     'model__max_depth': [7, 10, 15, 20],\n",
    "#     'model__max_leaf_nodes': [64, 128, 256, 512],\n",
    "#     'model__min_samples_split': [5,10,20,50]\n",
    "# }\n",
    "# randSearch = RandomizedSearchCV(rfPipeline, param_grid, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, n_iter=20)\n",
    "# randSearch.fit(xtrain,ytrainLog)\n",
    "# rfModel = randSearch.best_estimator_\n",
    "\n",
    "rfPipeline = Pipeline([\n",
    "    ('preprocessing', pipelineNoScaling),\n",
    "    ('model', RandomForestRegressor(n_estimators=400, max_depth=10, max_leaf_nodes=700, min_samples_split=10, n_jobs=-1))\n",
    "])\n",
    "rfModel = rfPipeline.fit(xtrain,ytrainLog)\n",
    "\n",
    "predictionsLog = rfModel.predict(xtest)\n",
    "logRMSE = np.sqrt(np.mean((predictionsLog - ytestLog)**2))\n",
    "print(f\"Random Forest Log-space RMSE: {logRMSE}\")\n",
    "\n",
    "predictions = np.expm1(predictionsLog)\n",
    "originalRMSE = np.sqrt(np.mean((predictions - ytest)**2))\n",
    "print(f\"Random Forest Original-space RMSE: {originalRMSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e055270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Log-space RMSE: 0.16802925703107705\n",
      "Adaboost Original-space RMSE: 31145.577096538374\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost w/ Decision Trees\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# adaPipeline = Pipeline([\n",
    "#     ('preprocessing', pipelineNoScaling),\n",
    "#     ('model', AdaBoostRegressor(DecisionTreeRegressor(), n_estimators=200, learning_rate=.25))\n",
    "# ])\n",
    "# param_grid = {\n",
    "#     'model__estimator__max_depth': [7, 10, 15, 20],\n",
    "#     'model__estimator__max_leaf_nodes': [64, 128, 256, 512],\n",
    "#     'model__estimator__min_samples_split': [5,10,20,50]\n",
    "# }\n",
    "# randSearch = RandomizedSearchCV(adaPipeline, param_grid, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, n_iter=20)\n",
    "# randSearch.fit(xtrain,ytrainLog)\n",
    "# adaModel = randSearch.best_estimator_\n",
    "\n",
    "adaPipeline = Pipeline([\n",
    "    ('preprocessing', pipelineNoScaling),\n",
    "    ('model', AdaBoostRegressor(DecisionTreeRegressor(max_depth=15, max_leaf_nodes=512, min_samples_split=15), n_estimators=200, learning_rate=.2))\n",
    "])\n",
    "adaModel = adaPipeline.fit(xtrain,ytrainLog)\n",
    "\n",
    "predictionsLog = adaModel.predict(xtest)\n",
    "logRMSE = np.sqrt(np.mean((predictionsLog - ytestLog)**2))\n",
    "print(f\"Adaboost Log-space RMSE: {logRMSE}\")\n",
    "\n",
    "predictions = np.expm1(predictionsLog)\n",
    "originalRMSE = np.sqrt(np.mean((predictions - ytest)**2))\n",
    "print(f\"Adaboost Original-space RMSE: {originalRMSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e28d526c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Log-space RMSE: 0.16355706352282345\n",
      "Gradient Boosting Original-space RMSE: 33283.53221073267\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# gbPipeline = Pipeline([\n",
    "#     ('preprocessing', pipelineNoScaling),\n",
    "#     ('model', GradientBoostingRegressor(max_depth=15, max_leaf_nodes=600, min_samples_split=10))\n",
    "# ])\n",
    "\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [.05, .1, .25, .5, .75],\n",
    "#     'model__n_estimators': [100, 200, 350, 500]\n",
    "# }\n",
    "\n",
    "# randSearch = RandomizedSearchCV(gbPipeline, param_grid, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, n_iter=20)\n",
    "# randSearch.fit(xtrain,ytrainLog)\n",
    "# gbModel = randSearch.best_estimator_\n",
    "\n",
    "gbPipeline = Pipeline([\n",
    "    ('preprocessing', pipelineNoScaling),\n",
    "    ('model', GradientBoostingRegressor(max_depth=10, max_leaf_nodes=512, min_samples_split=10, learning_rate=.1, n_estimators=200))\n",
    "])\n",
    "gbModel = gbPipeline.fit(xtrain,ytrainLog)\n",
    "\n",
    "predictionsLog = gbModel.predict(xtest)\n",
    "logRMSE = np.sqrt(np.mean((predictionsLog - ytestLog)**2))\n",
    "print(f\"Gradient Boosting Log-space RMSE: {logRMSE}\")\n",
    "\n",
    "predictions = np.expm1(predictionsLog)\n",
    "originalRMSE = np.sqrt(np.mean((predictions - ytest)**2))\n",
    "print(f\"Gradient Boosting Original-space RMSE: {originalRMSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d2103b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catboost Log-space RMSE: 0.12204169093735445\n",
      "Catboost Original-space RMSE: 22274.93661434924\n"
     ]
    }
   ],
   "source": [
    "# CatBoost \n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def fill_categorical_na(X):\n",
    "    X_copy = X.copy()\n",
    "    for col in catBoostVars:\n",
    "        X_copy[col] = X_copy[col].fillna('Missing')\n",
    "    return X_copy\n",
    "\n",
    "catBoostVars = catVars[:-3] \n",
    "\n",
    "catPipeline = Pipeline([\n",
    "    ('imputer', FunctionTransformer(fill_categorical_na)),\n",
    "    ('model', CatBoostRegressor(cat_features=catBoostVars,logging_level=\"Silent\", thread_count=-1))\n",
    "])\n",
    "\n",
    "catModel = catPipeline.fit(xtrain, ytrainLog)\n",
    "\n",
    "predictionsLog = catModel.predict(xtest)\n",
    "logRMSE = np.sqrt(np.mean((predictionsLog - ytestLog)**2))\n",
    "print(f\"Catboost Log-space RMSE: {logRMSE}\")\n",
    "\n",
    "predictions = np.expm1(predictionsLog)\n",
    "originalRMSE = np.sqrt(np.mean((predictions - ytest)**2))\n",
    "print(f\"Catboost Original-space RMSE: {originalRMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baac0aaf",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbc0474f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Log-space RMSE: 0.1275095823366899\n",
      "Stacking Original-space RMSE: 23769.92068206647\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "stack = StackingRegressor(\n",
    "    estimators=[    \n",
    "        (\"elasticNet\", elasticNetModel),\n",
    "        (\"randForest\", rfModel),\n",
    "        (\"ada\", adaModel),\n",
    "        (\"catBoost\", catModel)\n",
    "    ],\n",
    "    final_estimator=Ridge(alpha=3),\n",
    "    cv=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stack.fit(xtrain,ytrainLog)\n",
    "\n",
    "predictionsLog = stack.predict(xtest)\n",
    "logRMSE = np.sqrt(np.mean((predictionsLog - ytestLog)**2))\n",
    "print(f\"Stacking Log-space RMSE: {logRMSE}\")\n",
    "\n",
    "predictions = np.expm1(predictionsLog)\n",
    "originalRMSE = np.sqrt(np.mean((predictions - ytest)**2))\n",
    "print(f\"Stacking Original-space RMSE: {originalRMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27639fa",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca115835",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals.loc[:,numVars] = xvals.loc[:,numVars].fillna(0)\n",
    "submissionData.loc[:,numVars] = submissionData.loc[:,numVars].fillna(0)\n",
    "\n",
    "transformX(xvals)\n",
    "transformX(submissionData)\n",
    "yvalsLog = np.log1p(yvals)\n",
    "\n",
    "stack.fit(xvals,yvalsLog)\n",
    "predictionsLog = stack.predict(submissionData)\n",
    "predictions = np.expm1(predictionsLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06e0cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Id': submissionData[\"Id\"],\n",
    "    'SalePrice': predictions\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7e0282",
   "metadata": {},
   "source": [
    "Final Kaggle Score: .12214\n",
    "\n",
    "Ideas on how to get lower:\n",
    "\n",
    " - LightGBM, XGBoost models (stack: elasticnet, catboost, lightgbm, xgboost, random forest)\n",
    " - More feature engineering\n",
    " - Fine tune CatBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
