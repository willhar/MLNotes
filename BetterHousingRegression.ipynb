{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca32bc9",
   "metadata": {},
   "source": [
    "# Better Housing Regression w/ Ensemble Models\n",
    "\n",
    "\n",
    "Data from https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data\n",
    "\n",
    "Goal: beat the basic regression done in HousingRegression.ipynb. \n",
    "\n",
    "Score to beat: .14834 (lower is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f6ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d46241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "trainData = pd.read_csv(\"datasets/train.csv\")\n",
    "submissionData = pd.read_csv(\"datasets/test.csv\")\n",
    "\n",
    "yvals = trainData[\"SalePrice\"].copy()\n",
    "xvals = trainData.drop(columns=\"SalePrice\")\n",
    "price_bins = pd.qcut(yvals, q=8)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(xvals, yvals, test_size=.15, stratify=price_bins)\n",
    "\n",
    "ytrainLog = np.log1p(ytrain)\n",
    "ytestLog = np.log1p(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521417e3",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df7e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain[\"TotalSF\"] = xtrain[\"GrLivArea\"] + xtrain[\"TotalBsmtSF\"]\n",
    "xtrain[\"QualityArea\"] = xtrain[\"OverallQual\"] * xtrain[\"TotalSF\"]\n",
    "xtrain[\"TotalBath\"] = 0.5*xtrain[\"HalfBath\"] + xtrain[\"FullBath\"] + xtrain[\"BsmtFullBath\"] + 0.5*xtrain[\"BsmtHalfBath\"]\n",
    "xtrain[\"QualityScore\"] = xtrain[\"OverallQual\"] * xtrain[\"OverallCond\"]\n",
    "xtrain[\"BasementRatio\"] = xtrain[\"TotalBsmtSF\"] / (xtrain[\"GrLivArea\"]+1)\n",
    "xtrain[\"LivingSpaceRatio\"] = xtrain[\"GrLivArea\"] / (xtrain[\"LotArea\"]+1)\n",
    "\n",
    "xtest[\"TotalSF\"] = xtest[\"GrLivArea\"] + xtest[\"TotalBsmtSF\"]\n",
    "xtest[\"QualityArea\"] = xtest[\"OverallQual\"] * xtest[\"TotalSF\"]\n",
    "xtest[\"TotalBath\"] = 0.5*xtest[\"HalfBath\"] + xtest[\"FullBath\"] + xtest[\"BsmtFullBath\"] + 0.5*xtest[\"BsmtHalfBath\"]\n",
    "xtest[\"QualityScore\"] = xtest[\"OverallQual\"] * xtest[\"OverallCond\"]\n",
    "xtest[\"BasementRatio\"] = xtest[\"TotalBsmtSF\"] / (xtest[\"GrLivArea\"]+1)\n",
    "xtest[\"LivingSpaceRatio\"] = xtest[\"GrLivArea\"] / (xtest[\"LotArea\"]+1)\n",
    "\n",
    "catVars = list(xtrain.select_dtypes(exclude=\"number\").columns)\n",
    "catVars.append(\"MSSubClass\")\n",
    "catVars.append(\"OverallQual\")\n",
    "catVars.append(\"OverallCond\")\n",
    "numVars = list(xtrain.select_dtypes(include=\"number\").drop(columns=[\"Id\", \"MSSubClass\", \"OverallQual\", \"OverallCond\"]).columns)\n",
    "catIndices = [xtrain.columns.get_loc(col) for col in catVars]\n",
    "numIndices = [xtrain.columns.get_loc(col) for col in numVars]\n",
    "\n",
    "xtrain.loc[:,numVars] = xtrain.loc[:,numVars].fillna(0)\n",
    "xtest.loc[:,numVars] = xtest.loc[:,numVars].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18154003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "pipelineNoScaling = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), catIndices),\n",
    "    (\"num\", \"passthrough\", numIndices)\n",
    "])\n",
    "pipelineScaling = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), catIndices),\n",
    "    (\"num\", StandardScaler(), numIndices)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a76a3",
   "metadata": {},
   "source": [
    "### The Models\n",
    "\n",
    "1. Elastic Net -> the one built last time\n",
    "2. Bagging Regressor w/ Decision Trees\n",
    "3. Random Forest Regressor\n",
    "4. AdaBoost w/ Decision Trees\n",
    "5. Gradient Boosting\n",
    "6. CatBoost\n",
    "\n",
    "Lastly: use stacking to combine predictions from other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041fc79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net Validation RMSE: 25806.139752147643\n"
     ]
    }
   ],
   "source": [
    "# Elastic Net\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "netPipeline = Pipeline([\n",
    "    ('preprocessing', pipelineScaling),\n",
    "    ('model', ElasticNet())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__alpha': [0.01, 0.1, 1.0],\n",
    "    'model__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(netPipeline, param_grid, cv=10, \n",
    "                           scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(xtrain, ytrainLog)\n",
    "\n",
    "elasticNetModel = grid_search.best_estimator_\n",
    "\n",
    "predictions = elasticNetModel.predict(xtest)\n",
    "predictions = np.expm1(predictions)\n",
    "print(f\"Elastic Net Validation RMSE: {np.sqrt(np.mean((predictions-ytest)**2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653a57c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor Validation RMSE: 24188.360593894668\n"
     ]
    }
   ],
   "source": [
    "# Bagging Regressor w/ Decision Trees\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "bagPipeline = Pipeline([\n",
    "    ('preprocessing', pipelineNoScaling),\n",
    "    ('model', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'estimator__model__max_depth': [7, 10, 15, 20],\n",
    "    'estimator__model__max_leaf_nodes': [64, 128, 256, 512],\n",
    "    'estimator__model__min_samples_split': [5,10,20,50]\n",
    "}\n",
    "\n",
    "bagReg = BaggingRegressor(bagPipeline, n_jobs=-1, n_estimators=200, max_samples=.5)\n",
    "\n",
    "randSearch = RandomizedSearchCV(bagReg, param_grid, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, n_iter=20)\n",
    "randSearch.fit(xtrain,ytrainLog)\n",
    "\n",
    "bagModel = randSearch.best_estimator_\n",
    "\n",
    "predictions = bagModel.predict(xtest)\n",
    "predictions = np.expm1(predictions) \n",
    "\n",
    "print(f\"Bagging Regressor Validation RMSE: {np.sqrt(np.mean((predictions - ytest)**2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccad329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Validation RMSE: 23280.390477215875\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfPipeline = Pipeline([\n",
    "    ('preprocessing', pipelineNoScaling),\n",
    "    ('model', RandomForestRegressor(n_estimators=200))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__max_depth': [7, 10, 15, 20],\n",
    "    'model__max_leaf_nodes': [64, 128, 256, 512],\n",
    "    'model__min_samples_split': [5,10,20,50]\n",
    "}\n",
    "\n",
    "randSearch = RandomizedSearchCV(rfPipeline, param_grid, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, n_iter=20)\n",
    "randSearch.fit(xtrain,ytrainLog)\n",
    "rfModel = randSearch.best_estimator_\n",
    "\n",
    "predictions = rfModel.predict(xtest)\n",
    "predictions = np.expm1(predictions) \n",
    "\n",
    "print(f\"Random Forest Regressor Validation RMSE: {np.sqrt(np.mean((predictions - ytest)**2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e055270",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# AdaBoost w/ Decision Trees\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdaBoostRegressor\n\u001b[1;32m----> 4\u001b[0m adaPipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m      5\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessing\u001b[39m\u001b[38;5;124m'\u001b[39m, pipelineNoScaling),\n\u001b[0;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, AdaBoostRegressor(DecisionTreeRegressor(), n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.25\u001b[39m))\n\u001b[0;32m      7\u001b[0m ])\n\u001b[0;32m      9\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel__estimator__max_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m20\u001b[39m],\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel__estimator__max_leaf_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m512\u001b[39m],\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel__estimator__min_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m50\u001b[39m]\n\u001b[0;32m     13\u001b[0m }\n\u001b[0;32m     15\u001b[0m randSearch \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(adaPipeline, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg_root_mean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# AdaBoost w/ Decision Trees\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "adaPipeline = Pipeline([\n",
    "    ('preprocessing', pipelineNoScaling),\n",
    "    ('model', AdaBoostRegressor(DecisionTreeRegressor(), n_estimators=200, learning_rate=.25))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__estimator__max_depth': [7, 10, 15, 20],\n",
    "    'model__estimator__max_leaf_nodes': [64, 128, 256, 512],\n",
    "    'model__estimator__min_samples_split': [5,10,20,50]\n",
    "}\n",
    "\n",
    "randSearch = RandomizedSearchCV(adaPipeline, param_grid, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, n_iter=20)\n",
    "randSearch.fit(xtrain,ytrainLog)\n",
    "adaModel = randSearch.best_estimator_\n",
    "\n",
    "predictions = adaModel.predict(xtest)\n",
    "predictions = np.expm1(predictions) \n",
    "\n",
    "print(f\"AdaBoost Regressor Validation RMSE: {np.sqrt(np.mean((predictions - ytest)**2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28d526c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor Validation RMSE: 24916.04760030638\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbPipeline = Pipeline([\n",
    "    ('preprocessing', pipelineNoScaling),\n",
    "    ('model', GradientBoostingRegressor(max_depth=15, max_leaf_nodes=600, min_samples_split=10))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__learning_rate': [.05, .1, .25, .5, .75],\n",
    "    'model__n_estimators': [100, 200, 350, 500]\n",
    "}\n",
    "\n",
    "randSearch = RandomizedSearchCV(gbPipeline, param_grid, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, n_iter=20)\n",
    "randSearch.fit(xtrain,ytrainLog)\n",
    "gbModel = randSearch.best_estimator_\n",
    "\n",
    "predictions = gbModel.predict(xtest)\n",
    "predictions = np.expm1(predictions) \n",
    "\n",
    "print(f\"Gradient Boosting Regressor Validation RMSE: {np.sqrt(np.mean((predictions - ytest)**2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2103b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Regressor Validation RMSE: 22494.98428069441\n"
     ]
    }
   ],
   "source": [
    "# CatBoost \n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def fill_categorical_na(X):\n",
    "    X_copy = X.copy()\n",
    "    for col in catBoostVars:\n",
    "        X_copy[col] = X_copy[col].fillna('Missing')\n",
    "    return X_copy\n",
    "\n",
    "catBoostVars = catVars[:-3] \n",
    "\n",
    "catPipeline = Pipeline([\n",
    "    ('imputer', FunctionTransformer(fill_categorical_na)),\n",
    "    ('model', CatBoostRegressor(cat_features=catBoostVars,logging_level=\"Silent\", thread_count=-1))\n",
    "])\n",
    "\n",
    "catModel = catPipeline.fit(xtrain, ytrainLog)\n",
    "\n",
    "predictions = catModel.predict(xtest)\n",
    "predictions = np.expm1(predictions) \n",
    "\n",
    "print(f\"CatBoost Regressor Validation RMSE: {np.sqrt(np.mean((predictions - ytest)**2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baac0aaf",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc0474f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "stack = StackingRegressor(\n",
    "    estimators=[    \n",
    "        (\"elasticNet\", elasticNetModel),\n",
    "        (\"bagging\", bagModel),\n",
    "        (\"randForest\", rfModel),\n",
    "        (\"adaBoost\", adaModel),\n",
    "        (\"gradBoost\", gbModel),\n",
    "        (\"catBoost\", catModel)\n",
    "    ],\n",
    "    final_estimator=RandomForestRegressor(n_jobs=-1, n_estimators=10),\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "stack.fit(xtrain,ytrainLog)\n",
    "\n",
    "predictions = stack.predict(xtest)\n",
    "predictions = np.expm1(predictions) \n",
    "\n",
    "print(f\"CatBoost Regressor Validation RMSE: {np.sqrt(np.mean((predictions - ytest)**2))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
